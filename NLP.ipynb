{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb5b03a-6490-4eb1-aa95-ec81de5f85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68325f37-3962-428f-b18d-0572eb2931a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "books = pd.read_csv('books.csv')\n",
    "songs = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a126f8aa-ca65-48ca-94f2-8713a8abe922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venky\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  hey you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis:\n",
      "Negative: 0.2045\n",
      "Neutral: 0.5906\n",
      "Positive: 0.2049\n",
      "Max sentiment: Neutral\n",
      "Cleaned Text: hey you\n",
      "Matched Genres: []\n",
      "Extracted Genres: []\n",
      "\n",
      "Recommended Movies:\n",
      "Running Forever\n",
      "8 Days\n",
      "Growing Up Smith\n",
      "Midnight Cabaret\n",
      "Puss in Boots\n",
      "\n",
      "Recommended Books:\n",
      "A Commentary Upon the Gospel According to S. Luke\n",
      "NÃ¶ddebo Parsonage\n",
      "Palace Walk\n",
      "The Story of the Life of Lafayette\n",
      "Collections of the Massachusetts Historical Soceity\n",
      "\n",
      "Recommended Songs:\n",
      "Pene\n",
      "You're Losing Me\n",
      "Spades\n",
      "Nick Of Time\n",
      "Unchangeable\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  love the way you lie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis:\n",
      "Negative: 0.5534\n",
      "Neutral: 0.3401\n",
      "Positive: 0.1065\n",
      "Max sentiment: Negative\n",
      "Cleaned Text: love the way you lie\n",
      "Matched Genres: ['Romance']\n",
      "Extracted Genres: ['Romance']\n",
      "\n",
      "Recommended Movies:\n",
      "Killers\n",
      "Friends with Benefits\n",
      "The Young Victoria\n",
      "The Bodyguard\n",
      "New York, New York\n",
      "Genres for book recommendation: ['Romance']\n",
      "\n",
      "Recommended Books:\n",
      "The Once and Future King\n",
      "Sir Gawain and the Green Knight\n",
      "\n",
      "Recommended Songs:\n",
      "Alone\n",
      "Heaven\n",
      "It's Your Life\n",
      "National Anthem\n",
      "Cross My Heart\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  I love hindi movie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis:\n",
      "Negative: 0.0026\n",
      "Neutral: 0.0133\n",
      "Positive: 0.9841\n",
      "Max sentiment: Positive\n",
      "Cleaned Text: i love hindi movie\n",
      "Matched Genres: ['Romance', 'Bollywood', 'Hindi Songs']\n",
      "Extracted Genres: ['Romance', 'Bollywood', 'Hindi Songs']\n",
      "\n",
      "Recommended Movies:\n",
      "Killers\n",
      "The Love Guru\n",
      "Baahubali: The Beginning\n",
      "Friends with Benefits\n",
      "The Young Victoria\n",
      "Genres for book recommendation: ['Romance', 'Bollywood', 'Hindi Songs']\n",
      "\n",
      "Recommended Books:\n",
      "The Once and Future King\n",
      "Sir Gawain and the Green Knight\n",
      "\n",
      "Recommended Songs:\n",
      "Alone\n",
      "Heaven\n",
      "It's Your Life\n",
      "National Anthem\n",
      "Cross My Heart\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  bollywood songs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis:\n",
      "Negative: 0.0953\n",
      "Neutral: 0.7651\n",
      "Positive: 0.1396\n",
      "Max sentiment: Neutral\n",
      "Cleaned Text: bollywood songs\n",
      "Matched Genres: ['Music', 'Bollywood', 'Hindi Songs']\n",
      "Extracted Genres: ['Music', 'Bollywood', 'Hindi Songs']\n",
      "\n",
      "Recommended Movies:\n",
      "Tangled\n",
      "Frozen\n",
      "Happy Feet Two\n",
      "The Princess and the Frog\n",
      "The Hunchback of Notre Dame\n",
      "Genres for book recommendation: ['Music', 'Bollywood', 'Hindi Songs']\n",
      "\n",
      "Recommended Books:\n",
      "A Hard Day's Write, 3e\n",
      "Midnight Riders\n",
      "The Real Frank Zappa Book\n",
      "A Day in the Life\n",
      "Fourth of July mice\n",
      "\n",
      "Recommended Songs:\n",
      "Saturday Night Fish Fry\n",
      "I Believe In You\n",
      "Sitting At The Wheel\n",
      "Here's To My Lady\n",
      "Back In '72\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program\n"
     ]
    }
   ],
   "source": [
    "roberta = 'cardiffnlp/twitter-roberta-base-sentiment'  \n",
    "labels = ['Negative', 'Neutral','Positive']  \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    tweet_words = []\n",
    "\n",
    "    for word in text.split(' '):\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = \"http\"\n",
    "        tweet_words.append(word)\n",
    "\n",
    "    tweet_proc = \" \".join(tweet_words)\n",
    "    encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "    output = model(**encoded_tweet)\n",
    "    \n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    sentiment_probabilities = {labels[i]: scores[i] for i in range(len(labels))}\n",
    "    return sentiment_probabilities\n",
    "\n",
    "\n",
    "def extract_movies(text):\n",
    "    cleaned_text = ' '.join([word for word in text.split() if not word.startswith('@')])\n",
    "    cleaned_text = cleaned_text.lower()  \n",
    "    print(\"Cleaned Text:\", cleaned_text) \n",
    "\n",
    "    keyword_lst = {\n",
    "            'Crime': ['murder', 'detective', 'robbery', 'criminal', 'crime', 'investigation', 'mystery', 'thief', 'homicide', 'heist', 'police', 'law', 'suspect', 'evidence', 'forensic', 'courtroom', 'gang', 'underworld', 'corruption', 'witness', 'interrogation', 'fugitive', 'justice', 'prison', 'conspiracy', 'hostage', 'ransom', 'bribery', 'blackmail', 'organized crime', 'alibi', 'surveillance', 'fear', 'tension', 'distrust'],\n",
    "            \n",
    "            'Comedy': ['funny', 'humor', 'laugh', 'comedy', 'joke', 'hilarious', 'stand-up', 'satire', 'parody', 'slapstick', 'witty', 'gag', 'prank', 'skit', 'absurd', 'farce', 'silly', 'laughable', 'banter', 'punchline', 'caricature', 'clown', 'spoof', 'sarcasm', 'one-liner', 'comedic timing', 'laugh track', 'joy', 'playfulness', 'lighthearted'],\n",
    "                    \n",
    "            'Family': ['family', 'kids', 'children', 'parent', 'siblings', 'wholesome', 'bonding', 'generations', 'togetherness', 'values', 'babysitting', 'holiday', 'relatives', 'tradition', 'care', 'protection', 'support', 'warmth', 'nurturing'],\n",
    "                    \n",
    "            'Fantasy': ['magic', 'fantasy', 'supernatural', 'dragons', 'wizards', 'mythical', 'spells', 'enchantment', 'sorcery', 'creatures', 'medieval', 'prophecy', 'portal', 'parallel worlds', 'sword', 'epic', 'gods', 'fairy tale', 'otherworldly', 'ancient magic', 'awe', 'wonder', 'imagination', 'hope', 'desire'],\n",
    "                    \n",
    "            'Romance': ['love', 'romance', 'relationship', 'passion', 'affection', 'courtship', 'heartbreak', 'chemistry', 'soulmate', 'intimacy', 'flirting', 'proposal', 'jealousy', 'date', 'romantic', 'first love', 'longing', 'secret admirer', 'wedding', 'honeymoon', 'desire', 'empathy', 'trust', 'connection', 'vulnerability'],\n",
    "                    \n",
    "            'Horror': ['scary', 'horror', 'fear', 'ghost', 'monster', 'terror', 'creepy', 'haunted', 'psychological', 'gore', 'jump scare', 'nightmare', 'serial killer', 'demonic', 'possessed', 'curse', 'creature', 'slasher', 'undead', 'zombie', 'darkness', 'blood', 'evil', 'stalker', 'scream', 'panic', 'dread', 'unease', 'shock'],\n",
    "                    \n",
    "            'Action': ['action', 'fight', 'war', 'explosion', 'combat', 'chase', 'rescue', 'battle', 'mission', 'hero', 'assassin', 'showdown', 'weapon', 'gunfight', 'adrenaline', 'martial arts', 'special forces', 'escape', 'survival', 'spy', 'enemy', 'revolution', 'duel', 'vigilante', 'courage', 'fearlessness', 'bravery', 'determination', 'strength'],\n",
    "                    \n",
    "            'Sci_Fi': ['sci-fi', 'aliens', 'space', 'future', 'robot', 'technology', 'time travel', 'cyberpunk', 'extraterrestrial', 'spaceship', 'galaxy', 'parallel universe', 'dystopia', 'clones', 'virtual reality', 'artificial intelligence', 'cyborg', 'android', 'terraforming', 'wormhole', 'curiosity', 'discovery', 'inspiration', 'isolation'],\n",
    "                    \n",
    "            'Drama': ['drama', 'emotional', 'life', 'struggle', 'relationship', 'family', 'conflict', 'personal growth', 'tragedy', 'heartbreak', 'sacrifice', 'redemption', 'betrayal', 'self-discovery', 'crisis', 'moral dilemma', 'grief', 'injustice', 'reconciliation', 'forgiveness', 'despair', 'hope', 'resilience', 'sympathy', 'compassion'],\n",
    "                    \n",
    "            'Adventure': ['adventure', 'explore', 'journey', 'quest', 'discovery', 'expedition', 'danger', 'wilderness', 'treasure', 'survival', 'challenge', 'exploration', 'uncharted', 'island', 'daring', 'heroic', 'wild', 'legend', 'artifact', 'map', 'compass', 'excitement', 'curiosity', 'thrill', 'boldness', 'anticipation'],\n",
    "                    \n",
    "            'Music': ['music', 'singing', 'band', 'concert', 'song', 'performance', 'lyrics', 'guitar', 'piano', 'melody', 'festival', 'orchestra', 'musical', 'album', 'recording', 'rhythm', 'harmony', 'composer', 'soundtrack', 'hit single', 'tune', 'note', 'emotion', 'joy', 'creativity', 'passion', 'inspiration'],\n",
    "\n",
    "            'Fiction': ['storytelling', 'characters', 'narrative', 'conflict', 'identity', 'loneliness', 'despair', 'triumph', 'loss', 'hope', 'brokenness', 'resilience', 'emptiness', 'growth', 'emotional conflict'],\n",
    "\n",
    "            'Detective and Mystery': ['detective', 'mystery', 'suspense', 'isolation', 'fear', 'paranoia', 'puzzle', 'anxiety', 'revelation', 'tension', 'secrets', 'justice', 'uncertainty', 'doubt', 'desperation'],\n",
    "\n",
    "            'Christian Life': ['faith', 'struggle', 'forgiveness', 'redemption', 'inner peace', 'confusion', 'hope', 'guilt', 'empathy', 'spiritual conflict', 'forgiveness', 'compassion', 'sacrifice', 'healing'],\n",
    "\n",
    "            'Adventure': ['journey', 'exploration', 'loneliness', 'danger', 'excitement', 'isolation', 'risk', 'fear', 'survival', 'uncertainty', 'inner strength', 'bravery', 'wilderness', 'unknown', 'endurance'],\n",
    "\n",
    "            'American Fiction': ['individualism', 'struggle', 'freedom', 'identity', 'alienation', 'loss', 'hope', 'conflict', 'despair', 'rebuilding', 'brokenness', 'overcoming adversity', 'hope', 'disillusionment', 'dream'],\n",
    "\n",
    "            'Fantasy Fiction': ['magic', 'supernatural', 'myth', 'epic', 'quest', 'inner struggle', 'destiny', 'sacrifice', 'mystery', 'conflict', 'mythical beings', 'escape', 'prophecy', 'hope', 'overcoming darkness'],\n",
    "\n",
    "            'Science Fiction': ['technology', 'future', 'isolation', 'alienation', 'progress', 'paranoia', 'dystopia', 'utopia', 'fear', 'identity', 'existential crisis', 'innovation', 'struggle', 'hope', 'artificial intelligence'],\n",
    "\n",
    "            'Juvenile Fiction': ['innocence', 'friendship', 'adventure', 'growing up', 'emotional conflict', 'family', 'learning', 'hope', 'loneliness', 'belonging', 'self-discovery', 'fear', 'imagination', 'exploration', 'wholesome values'],\n",
    "\n",
    "            'Historical Fiction': ['history', 'struggle', 'sacrifice', 'identity', 'survival', 'loss', 'emotional depth', 'alienation', 'hope', 'triumph', 'cultural conflict', 'change', 'brokenness', 'resilience', 'renewal'],\n",
    "\n",
    "            'Drama': ['relationships', 'inner turmoil', 'heartbreak', 'loneliness', 'grief', 'emotional conflict', 'redemption', 'self-discovery', 'betrayal', 'loss', 'resilience', 'healing', 'brokenness', 'hope', 'reconciliation'],\n",
    "\n",
    "            'Country Life': ['nature', 'simplicity', 'community', 'loneliness', 'values', 'family bonds', 'conflict', 'peace', 'solitude', 'hardships', 'emotional growth', 'connection to the land', 'isolation', 'endurance', 'healing'],\n",
    "\n",
    "            'Arthurian Romances': ['chivalry', 'honor', 'epic quests', 'betrayal', 'sacrifice', 'inner conflict', 'loneliness', 'heroism', 'destiny', 'legend', 'tragedy', 'nobility', 'forgiveness', 'hope'],\n",
    "\n",
    "            'Dysfunctional Families': ['conflict', 'alienation', 'emotional struggle', 'loneliness', 'resentment', 'healing', 'grief', 'brokenness', 'communication issues', 'guilt', 'forgiveness', 'trauma', 'inner turmoil', 'reconciliation', 'hope'],\n",
    "\n",
    "            'Christmas Stories': ['family', 'togetherness', 'joy', 'loss', 'hope', 'emotional warmth', 'loneliness', 'compassion', 'healing', 'celebration', 'generosity', 'grief', 'connection', 'miracles', 'tradition'],\n",
    "\n",
    "            'Human Cloning': ['identity', 'existential crisis', 'alienation', 'technology', 'fear of the unknown', 'inner conflict', 'loneliness', 'struggle for meaning', 'moral dilemmas', 'isolation', 'self-awareness', 'loss of self', 'hope', 'humanity', 'consciousness'],\n",
    "\n",
    "            'Literary Collections': ['reflections', 'human experience', 'emotional depth', 'existentialism', 'grief', 'loneliness', 'hope', 'growth', 'self-discovery', 'resilience', 'fear', 'loss', 'joy', 'brokenness', 'rebuilding'],\n",
    "            \n",
    "            'Sex': ['sex','fuck','adult','desire', 'intimacy', 'passion', 'lust', 'physical attraction', 'romantic connection', 'sensuality', 'seduction', 'vulnerability', 'consent', 'taboo', 'infidelity', 'heartbreak', 'sexual tension', 'emotional connection', 'sexual identity', 'eroticism', 'temptation', 'jealousy', 'power dynamics', 'shame', 'guilt', 'pleasure', 'fantasy', 'regret', 'obsession', 'trust', 'betrayal', 'exploration', 'boundaries'],\n",
    "            \n",
    "            'Bollywood': ['hindi', 'bollywood', 'indian cinema', 'hindi movies', 'bollywood films'],\n",
    "\n",
    "            'Hindi Songs': ['hindi', 'bollywood', 'hindustani', 'desi', 'hindipop', 'hindimusic'],\n",
    "            \n",
    "            'Punjabi Songs': ['punjabi', 'bhangra', 'punjabimusic'],\n",
    "            \n",
    "            'Tamil Songs': ['tamil', 'kollywood', 'tamilmusic'],\n",
    "\n",
    "    }\n",
    "\n",
    "    matched_genres = []\n",
    "    for domain, keywords in keyword_lst.items():\n",
    "        if any(keyword in cleaned_text for keyword in keywords):\n",
    "            matched_genres.append(domain)\n",
    "    \n",
    "    print(\"Matched Genres:\", matched_genres)  # Debugging line\n",
    "    return matched_genres\n",
    "\n",
    "def recommend_genre_based_books(genre):\n",
    "    print(f\"Genres for book recommendation: {genre}\")\n",
    "\n",
    "    if 'categories' in books.columns and books['categories'].notna().any():\n",
    "        new_recommended = books[books['categories'].str.contains('|'.join(genre), case=False, na=False)]\n",
    "        return new_recommended['title'].head(5).tolist()\n",
    "    else:\n",
    "        print(\"No matching books found or 'categories' column missing.\")\n",
    "        return []\n",
    "\n",
    "def recommend_popular_books():\n",
    "    popular_books = books.sort_values(by='published_year', ascending=False)\n",
    "    return popular_books['title'].head(5).tolist()\n",
    "\n",
    "def recommend_genre_based_movies(genres):\n",
    "    recommended = movies[movies['tags'].str.contains('|'.join(genres), case=False)]\n",
    "    return recommended['title'].head(5).tolist()\n",
    "\n",
    "def recommend_popular_movies():\n",
    "    popular_movies = movies.sort_values(by='movie_id', ascending=False)\n",
    "    return popular_movies['title'].head(5).tolist()\n",
    "\n",
    "def recommend_genre_based_songs(genre):\n",
    "    # Correct usage of 'genre' instead of 'genres'\n",
    "    recommended = songs[songs['text'].str.contains('|'.join(genre), case=False)]\n",
    "    return recommended['song'].head(5).tolist()\n",
    "\n",
    "def recommend_popular_songs():\n",
    "    popular_song = songs.sort_values(by='artist', ascending=False)\n",
    "    return popular_song['song'].head(5).tolist()\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    user_input = input(\"Enter a text: \")\n",
    "\n",
    "    if user_input.lower() == 'exit':\n",
    "        print('Exiting the program')\n",
    "        break\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    sentiment_probs = analyze_sentiment(user_input)\n",
    "    max_sentiment = max(sentiment_probs, key=sentiment_probs.get)\n",
    "    print('\\nSentiment Analysis:')\n",
    "    for label, probability in sentiment_probs.items():\n",
    "        print(f\"{label}: {probability:.4f}\")\n",
    "    print(\"Max sentiment:\", max_sentiment)\n",
    "\n",
    "    # Extract genres from input text\n",
    "    extracted_movie_genres = extract_movies(user_input)\n",
    "    print(\"Extracted Genres:\", extracted_movie_genres)\n",
    "\n",
    "    # Movie recommendations\n",
    "    if extracted_movie_genres:\n",
    "        recommended_movies = recommend_genre_based_movies(extracted_movie_genres)\n",
    "    else:\n",
    "        recommended_movies = recommend_popular_movies()\n",
    "\n",
    "    if recommended_movies:\n",
    "        print(\"\\nRecommended Movies:\")\n",
    "        for movie in recommended_movies:\n",
    "            print(movie)\n",
    "    else:\n",
    "        print(\"No movies found in the dataset\")\n",
    "        \n",
    "    # Book recommendations\n",
    "    if extracted_movie_genres:\n",
    "        recommended_books = recommend_genre_based_books(extracted_movie_genres)\n",
    "    else:\n",
    "        recommended_books = recommend_popular_books()\n",
    "\n",
    "    if recommended_books:\n",
    "        print(\"\\nRecommended Books:\")\n",
    "        for book in recommended_books:\n",
    "            print(book)\n",
    "    else:\n",
    "        print(\"No books found in the dataset.\")\n",
    "\n",
    "    # Song recommendations\n",
    "    if extracted_movie_genres:\n",
    "        recommended_songs = recommend_genre_based_songs(extracted_movie_genres)\n",
    "    else:\n",
    "        recommended_songs = recommend_popular_songs()\n",
    "\n",
    "    if recommended_songs:\n",
    "        print(\"\\nRecommended Songs:\")\n",
    "        for song in recommended_songs:\n",
    "            print(song)\n",
    "    else:\n",
    "        print(\"No songs found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a2f58d3-2aa9-4616-bb64-5b02d607071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the tokenizer to a pickle file\n",
    "with open('sentiment_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Assuming you have a pandas DataFrame for books, movies, and songs datasets\n",
    "with open('books_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(books, f)\n",
    "\n",
    "with open('movies_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(movies, f)\n",
    "\n",
    "with open('songs_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(songs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164a693-2354-4f9d-9102-fbf5f988cf64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
